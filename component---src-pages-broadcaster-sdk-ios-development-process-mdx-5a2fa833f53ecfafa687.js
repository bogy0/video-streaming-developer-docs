(window.webpackJsonp=window.webpackJsonp||[]).push([[24],{g0WZ:function(e,a,t){"use strict";t.r(a),t.d(a,"_frontmatter",(function(){return s})),t.d(a,"default",(function(){return l}));t("91GP"),t("rGqo"),t("yt8O"),t("Btvt"),t("RW0V"),t("q1tI");var r=t("7ljp"),n=t("XbGe");t("qKvR");function o(){return(o=Object.assign||function(e){for(var a=1;a<arguments.length;a++){var t=arguments[a];for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(e[r]=t[r])}return e}).apply(this,arguments)}var s={},i={_frontmatter:s},c=n.a;function l(e){var a=e.components,t=function(e,a){if(null==e)return{};var t,r,n={},o=Object.keys(e);for(r=0;r<o.length;r++)t=o[r],a.indexOf(t)>=0||(n[t]=e[t]);return n}(e,["components"]);return Object(r.b)(c,o({},i,t,{components:a,mdxType:"MDXLayout"}),Object(r.b)("h2",null,"Step 1: Download SDK package"),Object(r.b)("p",null,"Request an SDK package from your Customer Success representative."),Object(r.b)("h2",null,"Step 2: Explore the SDK package"),Object(r.b)("p",null,"The provided zip archive contains the binary framework and a sample application."),Object(r.b)("h2",null,"Step 3: Create (or open) your project"),Object(r.b)("p",null,"Open the project that you would like to integrate the SDK in."),Object(r.b)("h2",null,"Step 4: Add the SDK to the project"),Object(r.b)("h3",null,"Add the framework"),Object(r.b)("p",null,"Drag ",Object(r.b)("inlineCode",{parentName:"p"},"IBMWatsonMediaBroadcasterSDK.xcframework")," into the Embedded Binaries section of your target."),Object(r.b)("h2",null,"Step 5: Setting up a Broadcaster"),Object(r.b)("p",null,"Setting up a broadcaster session in your app can be done in a few easy steps. The main component you instantiate is a ",Object(r.b)("inlineCode",{parentName:"p"},"IBMWatsonMediaBroadcaster"),". This class is responsible for the whole broadcast session - that is making connection with the broadcaster server, gathering the audio and video data through an object implementing the ",Object(r.b)("inlineCode",{parentName:"p"},"IBMWatsonMediaFrameSource")," protocol, present a preview of the captured frames using a class implementing ",Object(r.b)("inlineCode",{parentName:"p"},"IBMWatsonMediaPreviewPresenter"),". For optimal performance a broadcaster configuration object has to be passed when you initialize the broadcaster. ",Object(r.b)("inlineCode",{parentName:"p"},"IBMWatsonMediaBroadcasterConfig")," has presets for different video resolutions."),Object(r.b)("p",null,"For example:"),Object(r.b)("h4",null,"Objective-C"),Object(r.b)("pre",null,Object(r.b)("code",o({parentName:"pre"},{className:"language-objc"}),"@import IBMWatsonMediaBroadcasterSDK\n\nself.frameSource = [IBMWatsonMediaCaptureSessionFrameSource new];\nself.broadcastPreview = [[IBMWatsonMediaBroadcasterPreview alloc] initWithFrame:self.view.bounds];\nself.broadcasterConfig = [IBMWatsonMediaBroadcasterConfig configWithPreset:IBMWatsonMediaVideoPreset720];\nself.broadcaster = [[IBMWatsonMediaBroadcaster alloc] initWithFrameSource:self.frameSource config:self.broadcasterConfig];\nself.broadcaster.presenter = self.broadcastPreview;\n[self.broadcaster addListener:self];\n")),Object(r.b)("h4",null,"Swift"),Object(r.b)("pre",null,Object(r.b)("code",o({parentName:"pre"},{className:"language-swift"}),"import IBMWatsonMediaBroadcasterSDK\n\nframeSource = IBMWatsonMedia.CaptureSessionFrameSource()\nbroadcastPreview = IBMWatsonMedia.BroadcasterPreview(frame: view.bounds)\nbroadcasterConfig = IBMWatsonMedia.BroadcasterConfig(preset: .preset720)\nbroadcaster = IBMWatsonMedia.Broadcaster(frameSource: frameSource, config: broadcasterConfig)\nbroadcaster.presenter = broadcastPreview\nbroadcaster.add(self)\n")),Object(r.b)("p",null,"For using the default camera and microphone you have to provide the following keys in your application’s info.plist file:"),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},Object(r.b)("inlineCode",{parentName:"li"},"NSCameraUsageDescription")," - Short string describing how your app uses the camera."),Object(r.b)("li",{parentName:"ul"},Object(r.b)("inlineCode",{parentName:"li"},"NSMicrophoneUsageDescription")," - Short string describing how your app uses the microphone.")),Object(r.b)("h2",null,"Step 6: Broadcaster user interface"),Object(r.b)("p",null,"The IBM Video Streaming SDK doesn’t provide any user interface besides the captured preview. To help get started with building your own UI, you can find basic UI implementations in the sample apps."),Object(r.b)("h2",null,"Step 7: Setup a frame source"),Object(r.b)("p",null,"By now you have configured your broadcaster and it is ready to receive audio and video frames from its frame source. The IBM Video Streaming SDK offers several ",Object(r.b)("inlineCode",{parentName:"p"},"IBMWatsonMediaFrameSource")," implementations:"),Object(r.b)("ul",null,Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},Object(r.b)("inlineCode",{parentName:"p"},"IBMWatsonMediaCaptureSessionFrameSource")," can use the cameras and microphones of your device and capture audio and video frames to be broadcasted.")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},Object(r.b)("inlineCode",{parentName:"p"},"IBMWatsonMediaAssetFrameSource")," can be used to broadcast prerecorded media or inject a video into a live broadcast.")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},Object(r.b)("inlineCode",{parentName:"p"},"IBMWatsonMediaScreenCaptureFrameSource")," makes possible to broadcast the content of a screen.")),Object(r.b)("li",{parentName:"ul"},Object(r.b)("p",{parentName:"li"},Object(r.b)("inlineCode",{parentName:"p"},"IBMWatsonMediaCompositeFrameSource")," allos to combine several farme sources for effects like picture in picture."))),Object(r.b)("p",null,"For more detailed information see the reference documentation."),Object(r.b)("p",null,"In order to access a capture device (camera or microphone) you may need to get permissions from the end user.\n",Object(r.b)("inlineCode",{parentName:"p"},"IBMWatsonMediaCaptureSessionFrameSource")," has a built-in feature to detect if the host app has adequate access privileges to use the on-device microphones and cameras:"),Object(r.b)("h4",null,"Objective-C"),Object(r.b)("pre",null,Object(r.b)("code",o({parentName:"pre"},{className:"language-objc"}),"[frameSource requestPermissionIfNeeded:^(BOOL authorized) {\n    if (authorized) {\n        [self.broadcaster startCaptureWithCompletion:^(NSError * _Nullable error) {\n            //setup capture device related UI, etc.\n        }];\n    } else {\n        [self showAccessDeniedAlert];\n    }\n}];\n")),Object(r.b)("h4",null,"Swift"),Object(r.b)("pre",null,Object(r.b)("code",o({parentName:"pre"},{className:"language-swift"}),"frameSource.requestPermissionIfNeeded { isAuthorized in\n    if isAuthorized {\n        self.broadcaster.startCapture { error in\n            //setup capture device related UI, etc.\n        }\n    } else {\n        self.showAccessDeniedAlert()\n    }\n}\n")),Object(r.b)("h2",null,"Step 8: Getting access to the broadcast server"),Object(r.b)("p",null,"To start the actual broadcast session, you need a Channel ID to broadcast to, and an access token which authenticates your broadcast. Both can be obtained using IBM Video Streaming Channel API. For further details, please refer the ",Object(r.b)("a",o({parentName:"p"},{href:"https://developers.video.ibm.com/channel-api/getting-started.html"}),"Channel API Documentation"),", and see a working example using the API in our sample app. Once you obtained the Channel ID and the access token you can use them to start the actual broadcast:"),Object(r.b)("h4",null,"Objective-C"),Object(r.b)("pre",null,Object(r.b)("code",o({parentName:"pre"},{className:"language-objc"}),"[self.broadcaster startBroadcastWithChannelID:<#channelID#> accessToken:<#accessToken#>];\n")),Object(r.b)("h4",null,"Swift"),Object(r.b)("pre",null,Object(r.b)("code",o({parentName:"pre"},{className:"language-swift"}),"broadcaster.startBroadcast(withChannelID: <#channelID#>, accessToken: <#accessToken#>)\n")),Object(r.b)("h2",null,"Step 9: Handle broadcaster callbacks"),Object(r.b)("p",null,Object(r.b)("inlineCode",{parentName:"p"},"IBMWatsonMediaBroadcaster")," uses ",Object(r.b)("inlineCode",{parentName:"p"},"IBMWatsonMediaBroadcasterDelegate")," protocol to inform its delegate about certain events, state changes and statistical data about the broadcast session."),Object(r.b)("h3",null,"State change callbacks"),Object(r.b)("p",null,"Use ",Object(r.b)("inlineCode",{parentName:"p"},"broadcasterDidStart:")," and ",Object(r.b)("inlineCode",{parentName:"p"},"broadcasterDidStop:")," to update your user interface when broadcast session starts and ends. Also you can monitor the actual state of your ongoing broadcast session listening to ",Object(r.b)("inlineCode",{parentName:"p"},"broadcaster:didChangeState:"),". This callback tells you if the connection is established, the broadcast is running or there is still data to be flushed before the broadcast is stopped completely."),Object(r.b)("p",null,"If broadcaster fails for some reason, ",Object(r.b)("inlineCode",{parentName:"p"},"broadcaster:didFailWithError:")," is called. You can use its ",Object(r.b)("inlineCode",{parentName:"p"},"error")," parameter to inspect the actual reason of failure."),Object(r.b)("h3",null,"Transmition related callbacks"),Object(r.b)("p",null,"Because video broadcast is sensitive to network condition changes, there are some callbacks which can be used to get information about the general quality of your broadcast session. You can monitor when the video encoder changes its preferred output bitrate with ",Object(r.b)("inlineCode",{parentName:"p"},"broadcaster:didChangeVideoBitrate:oldBitrate:")," delegate method."),Object(r.b)("p",null,"Also there is a callback which is called every second reporting statistics about the current session: ",Object(r.b)("inlineCode",{parentName:"p"},"broadcaster:outputFrameRate:outputBandwidth:actualVideoBitrate:preferredVideoBitrate:bufferLoad:bufferLimit:")," delegate method."))}l.isMDXComponent=!0}}]);
//# sourceMappingURL=component---src-pages-broadcaster-sdk-ios-development-process-mdx-5a2fa833f53ecfafa687.js.map